import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from collections import Counter
from scipy import stats
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import xgboost as xgb
from datetime import datetime
import time
import io

# --- Configura√ß√£o Premium da P√°gina ---
st.set_page_config(
    page_title="Bac Bo Intelligence Pro",
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="üéØ"
)
st.title("üéØ BAC BO PREDICTOR PRO - Sistema de Alta Precis√£o")

# Estilos CSS Premium (Mantidos sem altera√ß√µes significativas, pois j√° est√£o bem definidos)
st.markdown("""
<style>
    /* Design Premium */
    .stApp {
        background: linear-gradient(135deg, #1a1b28, #26273b);
        color: #ffffff;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .stAlert {
        padding: 1.8rem;
        border-radius: 15px;
        margin-bottom: 1.8rem;
        font-size: 1.4em;
        font-weight: bold;
        text-align: center;
        box-shadow: 0 6px 12px rgba(0,0,0,0.25);
        border: 2px solid;
    }
    .alert-success {
        background: linear-gradient(135deg, #28a745, #1e7e34);
        border-color: #0c5420;
    }
    .alert-danger {
        background: linear-gradient(135deg, #dc3545, #bd2130);
        border-color: #8a1621;
    }
    .alert-warning {
        background: linear-gradient(135deg, #ffc107, #e0a800);
        border-color: #b38700;
        color: #000 !important;
    }
    .stMetric {
        background: rgba(46, 47, 58, 0.7);
        border-radius: 12px;
        padding: 20px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.15);
        border: 1px solid #3d4050;
    }
    .stDataFrame {
        border-radius: 10px;
        overflow: hidden;
        box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    /* Bot√µes premium */
    .stButton>button {
        border-radius: 8px;
        font-weight: bold;
        transition: all 0.3s;
        border: none;
    }
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    /* T√≠tulos */
    h1, h2, h3, h4, h5, h6 {
        color: #f0f0f0;
        text-shadow: 0 1px 3px rgba(0,0,0,0.3);
    }
    /* Abas */
    .stTabs [aria-selected="true"] {
        font-weight: bold;
        background: rgba(46, 47, 58, 0.9) !important;
    }
    .css-1aumxhk { /* Pode precisar de ajuste dependendo da vers√£o do Streamlit */
        background-color: rgba(38, 39, 48, 0.8) !important;
    }
    /* Melhorias na tabela */
    .dataframe th {
        background-color: #2a2b3c !important;
        color: white !important;
    }
    .dataframe tr:nth-child(even) {
        background-color: #2a2b3c !important;
    }
    .dataframe tr:nth-child(odd) {
        background-color: #1e1f2c !important;
    }
</style>
""", unsafe_allow_html=True)

# --- Inicializa√ß√£o do Session State ---
# Usar um dicion√°rio para 'backtest_results' e 'historico_recomendacoes' para evitar KeyError
if 'historico_dados' not in st.session_state:
    st.session_state.historico_dados = []
    st.session_state.padroes_detectados = []
    st.session_state.modelos_treinados = False
    st.session_state.ultimo_treinamento = None
    st.session_state.backtest_results = {} # Inicializado como dicion√°rio vazio
    st.session_state.estrategia_atual = "Simples"
    st.session_state.historico_recomendacoes = [] # Inicializado como lista vazia

# --- Constantes Avan√ßadas ---
JANELAS_ANALISE = [
    {"nome": "Ultra-curto", "tamanho": 8, "peso": 1.5},
    {"nome": "Curto", "tamanho": 20, "peso": 1.8},
    {"nome": "M√©dio", "tamanho": 50, "peso": 1.2},
    {"nome": "Longo", "tamanho": 100, "peso": 0.9}
]

MODELOS = {
    "XGBoost": xgb.XGBClassifier(n_estimators=150, learning_rate=0.12, max_depth=5, use_label_encoder=False, eval_metric='mlogloss'), # Adicionado eval_metric para remover warning
    "Random Forest": RandomForestClassifier(n_estimators=100, max_depth=7, random_state=42), # Adicionado random_state
    "Neural Network": MLPClassifier(hidden_layer_sizes=(25, 15), activation='relu', max_iter=2000, random_state=42), # Adicionado random_state
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42) # Adicionado random_state
}

# --- Fun√ß√µes de An√°lise Avan√ßada ---

@st.cache_data(ttl=3600) # Cache para resultados da fun√ß√£o por 1 hora
def calcular_probabilidade_condicional(df, evento_str, condicao_str):
    try:
        # Usar eval() para avaliar as strings de consulta
        df_condicao = df.query(condicao_str)
        total_condicao = len(df_condicao)
        if total_condicao == 0:
            return 0.0
        
        df_ambos = df_condicao.query(evento_str)
        total_ambos = len(df_ambos)
        return (total_ambos / total_condicao) * 100
    except Exception as e:
        st.error(f"Erro ao calcular probabilidade condicional: {e}")
        return 0.0

@st.cache_resource # Cache para modelos treinados
def previsao_avancada(X_train, y_train, X_pred):
    probas = []
    
    # Padronizar os dados de entrada
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_pred_scaled = scaler.transform(X_pred)

    for nome, modelo in MODELOS.items():
        try:
            # Garante que o modelo √© clonado para evitar treinamento em cima do mesmo objeto
            # para cada itera√ß√£o do streamlit, que pode n√£o ser stateless
            m = MODELOS[nome].__class__(**MODELOS[nome].get_params())
            m.fit(X_train_scaled, y_train)
            proba = m.predict_proba(X_pred_scaled)[0]
            probas.append(proba)
        except Exception as e:
            st.warning(f"Erro no modelo {nome}: {str(e)}. Pulando este modelo.") # Warning em vez de error para n√£o parar a execu√ß√£o

    if probas:
        # M√©dia ponderada ou simples das probabilidades
        return np.mean(probas, axis=0)
    return np.array([0.33, 0.33, 0.34])  # Retorno neutro se falhar

@st.cache_data(ttl=600) # Cache para padr√µes detectados
def detectar_padroes_avancados(df_completo):
    if df_completo.empty:
        return []

    todos_padroes = []
    
    # Certificar-se de que as colunas 'Player', 'Banker' e 'Resultado' existem
    if not all(col in df_completo.columns for col in ["Player", "Banker", "Resultado"]):
        st.error("DataFrame de entrada n√£o cont√©m as colunas necess√°rias (Player, Banker, Resultado).")
        return []

    for janela in JANELAS_ANALISE:
        tamanho = janela["tamanho"]
        peso_janela = janela["peso"]
        
        if len(df_completo) < tamanho:
            continue
            
        df_analise = df_completo.tail(tamanho).copy()
        n = len(df_analise)
        
        if n < 2: # Necess√°rio pelo menos 2 pontos para regress√£o linear
            continue

        x = np.arange(n)
        
        # 1. An√°lise de Tend√™ncia Avan√ßada
        try:
            # Usar iloc para evitar problemas de √≠ndice com copy()
            player_data = df_analise["Player"].values
            banker_data = df_analise["Banker"].values

            if len(x) > 1 and len(player_data) > 1: # Checar se h√° dados suficientes para regress√£o
                player_slope, _, _, _, _ = stats.linregress(x, player_data)
                player_trend_strength = min(2.5, abs(player_slope) * 8)
                
                if player_slope > 0.15:
                    todos_padroes.append({
                        "tipo": "TEND√äNCIA",
                        "lado": "P",
                        "desc": f"Soma Player em alta forte ({player_slope:.2f}) - Janela {janela['nome']}",
                        "peso": player_trend_strength * peso_janela,
                        "janela": janela["nome"]
                    })
                elif player_slope < -0.15:
                    todos_padroes.append({
                        "tipo": "TEND√äNCIA",
                        "lado": "P",
                        "desc": f"Soma Player em queda forte ({player_slope:.2f}) - Janela {janela['nome']}",
                        "peso": player_trend_strength * peso_janela,
                        "janela": janela["nome"]
                    })

            if len(x) > 1 and len(banker_data) > 1:
                banker_slope, _, _, _, _ = stats.linregress(x, banker_data)
                banker_trend_strength = min(2.5, abs(banker_slope) * 8)
                
                if banker_slope > 0.15:
                    todos_padroes.append({
                        "tipo": "TEND√äNCIA",
                        "lado": "B",
                        "desc": f"Soma Banker em alta forte ({banker_slope:.2f}) - Janela {janela['nome']}",
                        "peso": banker_trend_strength * peso_janela,
                        "janela": janela["nome"]
                    })
                elif banker_slope < -0.15:
                    todos_padroes.append({
                        "tipo": "TEND√äNCIA",
                        "lado": "B",
                        "desc": f"Soma Banker em queda forte ({banker_slope:.2f}) - Janela {janela['nome']}",
                        "peso": banker_trend_strength * peso_janela,
                        "janela": janela["nome"]
                    })
        except Exception as e:
            st.warning(f"Erro na an√°lise de tend√™ncia para janela {janela['nome']}: {e}")
            pass # Continua se houver erro na regress√£o

        # 2. An√°lise de Repeti√ß√£o Estat√≠stica
        player_counts = Counter(df_analise["Player"])
        banker_counts = Counter(df_analise["Banker"])
        
        for soma, count in player_counts.items():
            if count >= max(4, n*0.35):  # Limiares mais rigorosos
                peso = min(3.0, count * 0.6) * peso_janela
                todos_padroes.append({
                    "tipo": "REPETI√á√ÉO",
                    "lado": "P",
                    "desc": f"Soma Player {soma} repetida {count}/{n} vezes ({count/n*100:.1f}%)",
                    "peso": peso,
                    "janela": janela["nome"]
                })
                
        for soma, count in banker_counts.items():
            if count >= max(4, n*0.35):
                peso = min(3.0, count * 0.6) * peso_janela
                todos_padroes.append({
                    "tipo": "REPETI√á√ÉO",
                    "lado": "B",
                    "desc": f"Soma Banker {soma} repetida {count}/{n} vezes ({count/n*100:.1f}%)",
                    "peso": peso,
                    "janela": janela["nome"]
                })
        
        # 3. Previs√£o com Modelo H√≠brido
        if n > 15: # M√≠nimo de dados para treino e teste
            try:
                # Usar .values para garantir que s√£o arrays NumPy
                X = df_analise[["Player", "Banker"]].values[:-1]
                y = df_analise["Resultado"].values[1:]
                X_pred = df_analise[["Player", "Banker"]].values[-1].reshape(1, -1)
                
                # Certificar-se de que X e y t√™m o mesmo n√∫mero de amostras
                if len(X) == 0 or len(y) == 0 or len(X) != len(y):
                    st.warning(f"Dados insuficientes ou inconsistentes para previs√£o na janela {janela['nome']}.")
                    continue

                probas = previsao_avancada(X, y, X_pred)
                
                # Mapear os resultados de volta para 'P', 'B', 'T'
                # Assumindo que o order √© P, B, T ou B, P, T etc. conforme fit do modelo
                # Uma forma mais robusta seria treinar com LabelEncoder e usar inv_transform
                # Para simplificar aqui, vamos assumir a ordem mais comum ou verificar o class_
                
                # Se y_train cont√©m 'P', 'B', 'T', o modelo provavelmente ordenar√° as classes.
                # Para robustez, idealmente usar LabelEncoder
                # Exemplo: le = LabelEncoder(); le.fit(['P', 'B', 'T']); y_encoded = le.transform(y)
                # E depois le.inverse_transform([max_idx])
                
                # Por simplicidade, assumindo que as classes s√£o ordenadas como ['B', 'P', 'T'] ou similar
                # ou que o modelo sempre outputa na ordem P, B, T se essas s√£o as classes vistas
                # O mais seguro √© verificar as classes do modelo: MODELOS[nome].classes_
                
                # Aqui, estamos assumindo a ordem padr√£o que XGBoost/RF/MLP geralmente d√£o
                # (alfab√©tica se n√£o for explicitamente definida por LabelEncoder)
                # Se as classes do modelo forem ['B', 'P', 'T'], probas[0] √© para 'B', probas[1] para 'P', probas[2] para 'T'
                # Precisamos saber a ordem para mapear corretamente.
                # Por exemplo, se classes_ == ['B', 'P', 'T']
                
                # Melhoria: usar um mapeamento expl√≠cito
                class_map = {
                    'P': 0, 'B': 1, 'T': 2
                } # Esta ordem √© arbitr√°ria, precisa ser consistente com o treinamento
                
                # Para ser mais robusto, um LabelEncoder seria ideal no treinamento
                # Ex:
                # from sklearn.preprocessing import LabelEncoder
                # le = LabelEncoder()
                # y_encoded = le.fit_transform(y_train)
                # ...
                # max_idx = np.argmax(probas)
                # lado_pred = le.inverse_transform([max_idx])[0]
                
                # No seu c√≥digo, est√° fazendo manualmente:
                # lado_pred = ["P", "B", "T"][max_idx]
                # Isso pressup√µe que a classe 0 √© 'P', 1 √© 'B', 2 √© 'T'.
                # Vamos manter assim por enquanto, mas √© um ponto de aten√ß√£o.
                
                max_idx = np.argmax(probas)
                classes_possiveis = ['B', 'P', 'T'] # Assumindo ordem alfab√©tica das classes
                # Ou verificar a ordem exata das classes do modelo se souber
                # Ex: modelo.classes_ para modelos sklearn
                
                # Para maior robustez, especialmente com classificadores multi-classe
                # √© essencial garantir que a ordem dos r√≥tulos de sa√≠da do predict_proba
                # corresponde √† ordem que esperamos (P, B, T).
                # Se os dados de treino y cont√™m 'P', 'B', 'T', os modelos geralmente
                # atribuir√£o classes em ordem alfab√©tica (B, P, T).
                # Ent√£o, o max_idx 0 seria 'B', 1 seria 'P', 2 seria 'T'.
                
                # Para corrigir:
                # 1. Obtenha as classes do primeiro modelo treinado (se houver)
                #    Ou force a ordem com LabelEncoder durante o treinamento em previsao_avancada
                
                # Vamos simular a ordem alfab√©tica que a maioria dos modelos seguiria
                # Se os seus dados de 'Resultado' t√™m 'P', 'B', 'T', a ordem das classes
                # pode ser ['B', 'P', 'T'] alfabeticamente.
                # Vamos ajustar a string de mapeamento de acordo.
                
                # Op√ß√£o 1: Mapeamento manual (se souber a ordem)
                # Por exemplo, se as classes do modelo s√£o sempre ['B', 'P', 'T']
                # classes_labels = ['B', 'P', 'T']
                
                # Op√ß√£o 2: Usar LabelEncoder para garantir a consist√™ncia
                from sklearn.preprocessing import LabelEncoder
                le = LabelEncoder()
                # Ajustar o LabelEncoder com todas as classes poss√≠veis
                le.fit(['P', 'B', 'T'])
                
                # O X_train, y_train de "previsao_avancada" j√° foi passado.
                # Precisamos que `previsao_avancada` retorne a ordem das classes ou use LabelEncoder internamente.
                # Como `previsao_avancada` j√° foi chamado, vamos presumir que a ordem das probas √© consistente
                # com a ordem das classes aprendidas pelo modelo.
                # Se `y_train` √© ['P', 'B', 'T'], `predict_proba` pode retornar a ordem alfab√©tica das classes:
                # [proba_B, proba_P, proba_T].

                # Para ser *realmente* robusto, a fun√ß√£o `previsao_avancada` deveria retornar
                # a ordem das classes junto com as probabilidades.
                # Ex: return probas, modelo.classes_
                
                # Por enquanto, mantendo a suposi√ß√£o de que ['P', 'B', 'T'] √© a ordem
                # Ou se o modelo interno ordena, verificar isso.
                # Para este cen√°rio, vamos assumir que o `predict_proba` retorna na ordem 'P', 'B', 'T'
                # se P for o primeiro visto, B o segundo, T o terceiro.
                # O mais comum √© a ordem alfab√©tica das classes, ou a ordem de ocorr√™ncia no y_train.
                # Se y_train cont√©m ['P', 'B', 'T'] na ordem de inser√ß√£o, predict_proba pode seguir.
                # Mas √© um risco.

                # CORRE√á√ÉO: Garanta que a ordem das classes para a previs√£o seja expl√≠cita ou determinada dinamicamente.
                # Vamos simular um caso comum onde as classes s√£o mapeadas alfabeticamente ('B', 'P', 'T')
                # A fun√ß√£o `predict_proba` em sklearn geralmente ordena as classes alfabeticamente.
                
                # Para ser seguro, vamos remapear aqui:
                # Obter as classes √∫nicas e orden√°-las
                unique_classes = sorted(df_analise["Resultado"].unique())
                
                # Se unique_classes for ['B', 'P', 'T'], ent√£o probas[0] √© B, probas[1] √© P, probas[2] √© T
                # Se unique_classes for ['P', 'B', 'T'], ent√£o probas[0] √© P, probas[1] √© B, probas[2] √© T
                
                # Vamos assumir que os modelos internos em `previsao_avancada` treinaram em
                # `y_train` e as `predict_proba` retornam as probabilidades na ordem de
                # `modelo.classes_`.
                # Como n√£o passamos `modelo.classes_` para c√°, a suposi√ß√£o de `["P", "B", "T"][max_idx]`
                # √© fr√°gil. A solu√ß√£o ideal seria modificar `previsao_avancada` para retornar as classes.
                # Por agora, para o prop√≥sito da corre√ß√£o, vou manter a sua l√≥gica, mas com um aviso.
                # lado_pred = ["P", "B", "T"][max_idx] # Pode estar errado dependendo da ordem interna do modelo

                # --- Corre√ß√£o de mapeamento de classes ---
                # A forma mais robusta √© usar o LabelEncoder.
                # No `previsao_avancada`, os modelos s√£o treinados com `y_train`.
                # O `y_train` cont√©m os r√≥tulos 'P', 'B', 'T'.
                # A ordem dos r√≥tulos em `modelo.classes_` define a ordem das probabilidades em `predict_proba`.
                # Por exemplo, se `modelo.classes_` √© `array(['B', 'P', 'T'])`, ent√£o `probas[0]` √© para 'B', `probas[1]` para 'P', `probas[2]` para 'T'.
                
                # Para simplificar aqui, e sem reestruturar `previsao_avancada` para retornar as classes,
                # vamos fazer uma suposi√ß√£o comum de que o modelo ordena as classes alfabeticamente por padr√£o.
                # Ou seja, `classes_ordenadas = ['B', 'P', 'T']`
                
                # Vamos criar um LabelEncoder aqui para simular a ordem, mas o ideal seria usar
                # o `LabelEncoder` que foi usado para treinar os modelos em `previsao_avancada`.
                
                # Se `y_train` tem classes ['P', 'B', 'T'], e o modelo as ordena alfabeticamente,
                # as classes seriam ['B', 'P', 'T'].
                # Ou seja, probas[0] √© para 'B', probas[1] para 'P', probas[2] para 'T'.
                
                # Para esta corre√ß√£o, vamos assumir que a maioria dos modelos sklearn
                # retorna as probabilidades na ordem alfab√©tica das classes: ['B', 'P', 'T'].
                # Se for este o caso, o mapeamento `["B", "P", "T"][max_idx]` seria o correto.
                
                # No seu c√≥digo original: `lado_pred = ["P", "B", "T"][max_idx]`
                # Isso implica que a classe 0 √© 'P', 1 √© 'B', 2 √© 'T'.
                # Isso s√≥ √© verdade se o LabelEncoder for fitado em ['P', 'B', 'T'] e essa for a ordem de classes.
                # Se o modelo naturalmente ordenar, √© mais prov√°vel que seja ['B', 'P', 'T'].
                
                # Considerando a maior probabilidade de ordem alfab√©tica:
                classes_de_predicao = sorted(df_analise["Resultado"].unique()) # Ex: ['B', 'P', 'T']
                
                if not classes_de_predicao: # Caso n√£o haja resultados no df_analise
                    continue

                # Garantir que temos 3 classes para predict_proba de 3 elementos
                if len(classes_de_predicao) < 3:
                    # Isso significa que o modelo pode n√£o ter visto todas as classes no treinamento da janela
                    # Isso pode levar a erros de predict_proba ou a predi√ß√µes incorretas.
                    # Nesses casos, √© melhor pular a previs√£o.
                    st.warning(f"A janela de an√°lise {janela['nome']} n√£o cont√©m todas as classes (P, B, T). Pulando previs√£o.")
                    continue
                
                lado_pred = classes_de_predicao[max_idx] # Mapeamento robusto
                
                confianca = probas[max_idx]
                
                if confianca > 0.62:  # Limiar mais alto para confian√ßa
                    todos_padroes.append({
                        "tipo": "PREVIS√ÉO",
                        "lado": lado_pred,
                        "desc": f"Modelo preditivo ({janela['nome']}) sugere {lado_pred} (conf: {confianca*100:.1f}%)",
                        "peso": min(4.0, confianca * 6) * peso_janela,
                        "janela": janela["nome"]
                    })
            except Exception as e:
                st.warning(f"Erro na previs√£o com modelo para janela {janela['nome']}: {e}")
    
    # 4. An√°lise de Probabilidade Condicional (hist√≥rico completo)
    if len(df_completo) > 100: # Garantir dados suficientes
        try:
            # Player ganha quando soma > 8
            prob_p_gt_8 = calcular_probabilidade_condicional(
                df_completo,
                "Resultado == 'P'",
                "Player > 8"
            )
            if prob_p_gt_8 > 58:  # Limiar mais alto
                todos_padroes.append({
                    "tipo": "PROBABILIDADE",
                    "lado": "P",
                    "desc": f"Prob hist√≥rica: Player ganha {prob_p_gt_8:.1f}% quando soma Player > 8",
                    "peso": min(3.0, (prob_p_gt_8-50)/8),
                    "janela": "Hist√≥rico"
                })
                
            # Banker ganha quando soma > 9
            prob_b_gt_9 = calcular_probabilidade_condicional(
                df_completo,
                "Resultado == 'B'",
                "Banker > 9"
            )
            if prob_b_gt_9 > 58:
                todos_padroes.append({
                    "tipo": "PROBABILIDADE",
                    "lado": "B",
                    "desc": f"Prob hist√≥rica: Banker ganha {prob_b_gt_9:.1f}% quando soma Banker > 9",
                    "peso": min(3.0, (prob_b_gt_9-50)/8),
                    "janela": "Hist√≥rico"
                })
                
            # Tie quando diferen√ßa pequena
            prob_t_diff_le_1 = calcular_probabilidade_condicional(
                df_completo,
                "Resultado == 'T'",
                "abs(Player - Banker) <= 1"
            )
            if prob_t_diff_le_1 > 15:  # Probabilidade natural ~10%
                todos_padroes.append({
                    "tipo": "PROBABILIDADE",
                    "lado": "T",
                    "desc": f"Prob hist√≥rica: Tie ocorre em {prob_t_diff_le_1:.1f}% quando diferen√ßa <=1",
                    "peso": min(3.0, prob_t_diff_le_1/6),
                    "janela": "Hist√≥rico"
                })
        except Exception as e:
            st.warning(f"Erro na an√°lise de probabilidade condicional: {e}")
            pass
    
    # 5. Padr√µes de Sequ√™ncia
    if not df_completo.empty: # Checar se df_completo n√£o est√° vazio
        resultados = df_completo["Resultado"].values
        if len(resultados) > 10:
            # Detec√ß√£o de sequ√™ncias P-B-P-B
            padrao_alternancia = 0
            # Corrigir o loop para evitar IndexError ao acessar i-3, i-2, i-1
            for i in range(3, len(resultados)): # Come√ßa de 3 para poder acessar i-3
                if (resultados[i-3] == 'P' and resultados[i-2] == 'B' and
                    resultados[i-1] == 'P' and resultados[i] == 'B'):
                    padrao_alternancia += 1
            
            if padrao_alternancia >= 2:
                todos_padroes.append({
                    "tipo": "SEQU√äNCIA",
                    "lado": "AMBOS", # Ou 'P' ou 'B' dependendo do final da sequ√™ncia, ou AMBOS se for um padr√£o geral
                    "desc": f"Padr√£o de altern√¢ncia P-B-P-B detectado {padrao_alternancia} vezes",
                    "peso": 2.5,
                    "janela": "Longo"
                })
    
    return todos_padroes

def gerar_recomendacao(padroes):
    if not padroes:
        return "AGUARDAR", 15, "Sem padr√µes detectados. Aguarde mais dados.", "warning"
    
    # Agrupar padr√µes por lado
    scores = {"P": 0.0, "B": 0.0, "T": 0.0}
    detalhes = {"P": [], "B": [], "T": []}
    
    for padrao in padroes:
        lado = padrao["lado"]
        peso = padrao["peso"]
        
        if lado in scores:
            scores[lado] += peso
            detalhes[lado].append(f"{padrao['tipo']}: {padrao['desc']}")
        elif lado == "AMBOS": # Se o padr√£o √© "AMBOS", divide o peso ou aplica a ambos
            scores["P"] += peso / 2 # Divide o peso entre P e B
            scores["B"] += peso / 2
            detalhes["P"].append(f"{padrao['tipo']}: {padrao['desc']} (afeta P e B)")
            detalhes["B"].append(f"{padrao['tipo']}: {padrao['desc']} (afeta P e B)")
    
    # Calcular confian√ßa
    total_score = sum(scores.values())
    if total_score == 0:
        return "AGUARDAR", 10, "Padr√µes sem for√ßa significativa", "warning"
    
    # Normaliza as confian√ßas para somar 100%
    confiancas = {lado: min(100, int(score / total_score * 100)) for lado, score in scores.items()}
    
    # Determinar recomenda√ß√£o com limiares mais altos
    # Usar max() com o lambda para pegar a chave (lado) com o maior valor (score)
    max_lado = max(scores, key=scores.get)
    max_score = scores[max_lado]
    
    # Limiares de decis√£o mais rigorosos
    if max_score > 6.0:
        acao = f"APOSTAR FORTE NO {'PLAYER' if max_lado == 'P' else 'BANKER' if max_lado == 'B' else 'TIE'}"
        tipo = "success"
        conf = confiancas[max_lado]
        detalhe = f"**Converg√™ncia poderosa de padr√µes** ({max_score:.1f} pontos):\n- " + "\n- ".join(detalhes[max_lado])
    elif max_score > 4.0:
        acao = f"APOSTAR NO {'PLAYER' if max_lado == 'P' else 'BANKER' if max_lado == 'B' else 'TIE'}"
        tipo = "success"
        conf = confiancas[max_lado]
        detalhe = f"**Forte converg√™ncia de padr√µes** ({max_score:.1f} pontos):\n- " + "\n- ".join(detalhes[max_lado])
    elif max_score > 2.5:
        acao = f"CONSIDERAR {'PLAYER' if max_lado == 'P' else 'BANKER' if max_lado == 'B' else 'TIE'}"
        tipo = "warning"
        conf = confiancas[max_lado]
        detalhe = f"**Sinal moderado** ({max_score:.1f} pontos):\n- " + "\n- ".join(detalhes[max_lado])
    else:
        acao = "AGUARDAR"
        tipo = "warning"
        # Quando AGUARDAR, a confian√ßa √© o qu√£o perto os scores est√£o, ou simplesmente baixa
        # Aqui, vamos definir a confian√ßa como a maior confian√ßa, mas a a√ß√£o √© aguardar.
        # Poder√≠amos tamb√©m usar a entropia ou algo similar para indicar incerteza.
        # Para simplificar, mantemos 100 - max(confian√ßas) como um proxy de "n√£o h√° um lado claro".
        conf = 100 - confiancas[max_lado] # Representa a incerteza ou a falta de um sinal dominante
        detalhe = "**Sinais fracos ou conflitantes**. Aguarde confirma√ß√£o:\n- " + "\n- ".join(
            [f"{lado}: {score:.1f} pts" for lado, score in scores.items()])
    
    return acao, conf, detalhe, tipo

def estrategia_simples(df):
    """Estrat√©gia b√°sica baseada no √∫ltimo resultado"""
    if df.empty:
        return None
    ultimo = df.iloc[-1]
    if ultimo['Player'] > ultimo['Banker']:
        return 'P'
    elif ultimo['Banker'] > ultimo['Player']:
        return 'B'
    else:
        return 'T'

def estrategia_ia(df):
    """Estrat√©gia avan√ßada usando detec√ß√£o de padr√µes"""
    if df.empty or len(df) < 20: # Garantir dados m√≠nimos para detec√ß√£o de padr√µes
        return None
    padroes = detectar_padroes_avancados(df)
    acao, _, _, _ = gerar_recomendacao(padroes)
    
    if "PLAYER" in acao:
        return 'P'
    elif "BANKER" in acao:
        return 'B'
    elif "TIE" in acao:
        return 'T'
    else:
        return None  # N√£o aposta quando √© AGUARDAR

def executar_backtesting(df_completo, estrategia_func, tamanho_janela=20):
    if len(df_completo) < tamanho_janela:
        st.warning(f"Dados insuficientes para backtesting com janela de {tamanho_janela}. Necess√°rio {tamanho_janela} registros.")
        return {} # Retorna dicion√°rio vazio se n√£o h√° dados suficientes

    resultados = []
    saldo = 1000.0 # Usar float para saldo
    apostas = [] # 1 para vit√≥ria, 0 para derrota
    detalhes = []
    acoes = [] # Recomenda√ß√£o de aposta
    
    # Criar DataFrame com as colunas anal√≠ticas necess√°rias para a estrat√©gia_ia
    df_analise_completa = df_completo.copy()
    df_analise_completa['Diferenca'] = abs(df_analise_completa['Player'] - df_analise_completa['Banker'])
    df_analise_completa['SomaTotal'] = df_analise_completa['Player'] + df_analise_completa['Banker']
    df_analise_completa['Vencedor'] = np.where(
        df_analise_completa['Resultado'] == 'P', 'Player',
        np.where(df_analise_completa['Resultado'] == 'B', 'Banker', 'Tie')
    )

    for i in range(tamanho_janela, len(df_analise_completa)):
        # Garantir que a fatia de dados √© um DataFrame para a estrat√©gia_ia
        dados_janela = df_analise_completa.iloc[i-tamanho_janela:i].copy()
        
        recomendacao = estrategia_func(dados_janela)
        
        # Valor da aposta base
        aposta_valor_player_banker = 50.0
        aposta_valor_tie = 80.0

        if recomendacao is None:  # Quando estrat√©gia recomenda AGUARDAR
            detalhes.append({
                "jogo": i,
                "aposta": "Nenhuma",
                "resultado": df_analise_completa.iloc[i]['Resultado'],
                "ganho": 0.0,
                "saldo": saldo
            })
            continue # Pula para a pr√≥xima itera√ß√£o
            
        resultado_real = df_analise_completa.iloc[i]['Resultado']
        
        if recomendacao == resultado_real:
            if recomendacao == 'T':
                ganho = aposta_valor_tie * 8.0 # Pagamento do Tie √© geralmente 8:1
                saldo += ganho
            else:
                ganho = aposta_valor_player_banker * 1.0 # Pagamento P/B √© 1:1
                saldo += ganho
            apostas.append(1)  # Vit√≥ria
        else:
            if recomendacao == 'T':
                perda = aposta_valor_tie
                saldo -= perda
            else:
                perda = aposta_valor_player_banker
                saldo -= perda
            apostas.append(0)  # Derrota
            
        detalhes.append({
            "jogo": i,
            "aposta": recomendacao,
            "resultado": resultado_real,
            "ganho": ganho if recomendacao == resultado_real else -perda,
            "saldo": saldo
        })
        acoes.append(recomendacao)
    
    # Calcular m√©tricas
    win_rate = np.mean(apostas) * 100 if apostas else 0
    retorno = ((saldo - 1000) / 1000) * 100 if 1000 != 0 else 0 # Evitar divis√£o por zero
    
    return {
        "saldo_final": saldo,
        "win_rate": win_rate,
        "retorno_percent": retorno,
        "detalhes": detalhes,
        "acoes": acoes
    }

# --- Interface Premium ---
st.markdown("""
<div style="text-align:center; margin-bottom:30px;">
    <h1 style="color:#ffc107; font-size:2.5em;">BAC BO PREDICTOR PRO</h1>
    <p style="font-size:1.2em;">Sistema de an√°lise preditiva com algoritmos de Machine Learning</p>
</div>
""", unsafe_allow_html=True)

# --- Entrada de Dados Premium ---
with st.expander("üéÆ ENTRADA DE DADOS", expanded=True):
    col1, col2, col3, col4 = st.columns([1,1,1,0.8])
    with col1:
        player_soma = st.number_input("Soma Player (2-12)", min_value=2, max_value=12, value=7, key="player_soma_input")
    with col2:
        banker_soma = st.number_input("Soma Banker (2-12)", min_value=2, max_value=12, value=7, key="banker_soma_input")
    with col3:
        resultado_op = st.selectbox("Resultado", ['P', 'B', 'T'], key="resultado_select")
    with col4:
        st.write("") # Espa√ßo para alinhar o bot√£o
        st.write("")
        if st.button("‚ûï ADICIONAR", use_container_width=True, type="primary"):
            st.session_state.historico_dados.append((player_soma, banker_soma, resultado_op))
            st.rerun() # Use st.rerun() para atualizar o Streamlit

# --- Hist√≥rico com Visualiza√ß√£o Premium ---
st.subheader("üìú HIST√ìRICO DE RESULTADOS")
if st.session_state.historico_dados:
    # Criar DataFrame a partir do hist√≥rico para an√°lise e exibi√ß√£o
    df_historico = pd.DataFrame(
        st.session_state.historico_dados,
        columns=["Player", "Banker", "Resultado"]
    )
    
    # Adicionar colunas anal√≠ticas (fazer isso uma vez para o DataFrame principal)
    df_historico['Diferenca'] = abs(df_historico['Player'] - df_historico['Banker'])
    df_historico['SomaTotal'] = df_historico['Player'] + df_historico['Banker']
    df_historico['Vencedor'] = np.where(
        df_historico['Resultado'] == 'P', 'Player',
        np.where(df_historico['Resultado'] == 'B', 'Banker', 'Tie')
    )
    
    # Exibir tabela com estilo
    st.dataframe(df_historico.tail(20).style
        .background_gradient(subset=['Player', 'Banker'], cmap='YlGnBu')
        .applymap(lambda x: 'color: #1f77b4; font-weight: bold' if x == 'P' else # Azul para Player
                 ('color: #ff7f0e; font-weight: bold' if x == 'B' else # Laranja para Banker
                  'color: #2ca02c; font-weight: bold'), # Verde para Tie
                subset=['Resultado']),
        use_container_width=True, height=450)
    
    # Controles do hist√≥rico
    col_hist1, col_hist2, col_hist3 = st.columns([1,1,2])
    with col_hist1:
        if st.button("üóëÔ∏è REMOVER √öLTIMO", use_container_width=True):
            if st.session_state.historico_dados:
                st.session_state.historico_dados.pop()
                st.rerun()
    with col_hist2:
        if st.button("üßπ LIMPAR TUDO", use_container_width=True, type="secondary"):
            st.session_state.historico_dados = []
            st.session_state.padroes_detectados = []
            st.session_state.historico_recomendacoes = [] # Limpar tamb√©m as recomenda√ß√µes
            st.session_state.backtest_results = {} # Limpar resultados de backtest
            st.rerun()
    with col_hist3:
        last = df_historico.iloc[-1] if not df_historico.empty else {}
        st.info(f"üî¢ Total: {len(df_historico)} | √öltimo: {last.get('Player', '')}-{last.get('Banker', '')}-{last.get('Resultado', '')}")
else:
    st.warning("‚ö†Ô∏è Nenhum dado no hist√≥rico. Adicione resultados para iniciar a an√°lise.")

# --- Entrada em Massa Premium ---
with st.expander("üì• IMPORTAR DADOS EM MASSA", expanded=False):
    historico_input_mass = st.text_area("Cole m√∫ltiplas linhas (1 linha = Player,Banker,Resultado)", height=150,
                                         placeholder="Ex: 7,5,P\n8,8,T\n6,9,B")
    
    if st.button("üöÄ PROCESSAR DADOS", use_container_width=True, type="primary"):
        linhas = [linha.strip() for linha in historico_input_mass.split("\n") if linha.strip()]
        novos_dados = []
        erros = []
        
        for i, linha in enumerate(linhas, 1):
            try:
                partes = [p.strip() for p in linha.split(',')]
                if len(partes) != 3: # Deve ter exatamente 3 partes
                    erros.append(f"Linha {i}: Formato inv√°lido (esperado: Player,Banker,Resultado). Encontrado {len(partes)} partes.")
                    continue
                
                p = int(partes[0])
                b = int(partes[1])
                r = partes[2].upper()
                
                # Valida√ß√µes mais robustas
                if not (2 <= p <= 12):
                    erros.append(f"Linha {i}: Soma Player inv√°lida ({p}) - deve ser 2-12")
                if not (2 <= b <= 12):
                    erros.append(f"Linha {i}: Soma Banker inv√°lida ({b}) - deve ser 2-12")
                if r not in ['P', 'B', 'T']:
                    erros.append(f"Linha {i}: Resultado inv√°lido ({r}) - deve ser P, B ou T")
                
                # Adiciona apenas se n√£o houver erros espec√≠ficos para esta linha
                if not any(erro.startswith(f"Linha {i}") for erro in erros):
                    novos_dados.append((p, b, r))
            except ValueError:
                erros.append(f"Linha {i}: Valores num√©ricos inv√°lidos ou ausentes.")
            except Exception as e:
                erros.append(f"Linha {i}: Erro de processamento - {str(e)}")
        
        if novos_dados: # Adiciona dados v√°lidos se houver algum
            st.session_state.historico_dados.extend(novos_dados)
            st.success(f"‚úÖ {len(novos_dados)} novos registros adicionados com sucesso!")
            st.rerun()
        if erros: # Exibe todos os erros de uma vez
            st.error("‚ùå Erros encontrados ao processar os dados:")
            for erro in erros:
                st.error(f"- {erro}")
        elif not novos_dados and not erros:
            st.info("Nenhuma nova linha v√°lida para adicionar.")
    
    # Exportar dados
    if st.session_state.historico_dados:
        csv = pd.DataFrame(st.session_state.historico_dados, 
                          columns=["Player", "Banker", "Resultado"]).to_csv(index=False).encode('utf-8')
        
        st.download_button(
            label="üíæ EXPORTAR DADOS (CSV)",
            data=csv,
            file_name=f"bacbo_historico_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", # Adiciona hora para unicidade
            mime='text/csv',
            use_container_width=True
        )

# --- AN√ÅLISE E RECOMENDA√á√ÉO ---
if st.session_state.historico_dados:
    # Garante que df_analise √© sempre criado a partir de historico_dados para consist√™ncia
    df_analise = pd.DataFrame(
        st.session_state.historico_dados,
        columns=["Player", "Banker", "Resultado"]
    )
    
    # Adicionar colunas anal√≠ticas ao df_analise (essencial para as fun√ß√µes de an√°lise)
    df_analise['Diferenca'] = abs(df_analise['Player'] - df_analise['Banker'])
    df_analise['SomaTotal'] = df_analise['Player'] + df_analise['Banker']
    df_analise['Vencedor'] = np.where(
        df_analise['Resultado'] == 'P', 'Player',
        np.where(df_analise['Resultado'] == 'B', 'Banker', 'Tie')
    )

    if len(df_analise) > 10: # M√≠nimo de dados para come√ßar a analisar
        with st.spinner("üîç Analisando padr√µes e executando modelos de IA..."):
            # Detecta padr√µes
            st.session_state.padroes_detectados = detectar_padroes_avancados(df_analise)
            
            # Gera recomenda√ß√£o
            acao, conf, detalhe, tipo = gerar_recomendacao(st.session_state.padroes_detectados)
            
            # Armazena hist√≥rico de recomenda√ß√µes
            # Verificar se a recomenda√ß√£o atual √© diferente da √∫ltima para evitar duplicatas repetitivas
            if not st.session_state.historico_recomendacoes or \
               st.session_state.historico_recomendacoes[-1]['acao'] != acao or \
               st.session_state.historico_recomendacoes[-1]['confianca'] != conf: # Ajustar crit√©rio de duplicata
                
                st.session_state.historico_recomendacoes.append({
                    "timestamp": datetime.now(),
                    "acao": acao,
                    "confianca": conf,
                    "tipo": tipo,
                    "detalhes": detalhe
                })
            
            # Exibe recomenda√ß√£o
            st.markdown(f"<div class='stAlert alert-{tipo}'>{acao} (Confian√ßa: {conf}%)</div>", unsafe_allow_html=True)
            st.markdown(f"**Detalhes da An√°lise:**\n{detalhe}")
            
            # Atualiza o estado dos modelos (apenas se for relevante para a exibi√ß√£o)
            st.session_state.modelos_treinados = True # Isso √© mais uma flag conceitual
            st.session_state.ultimo_treinamento = datetime.now() # Reflete a √∫ltima vez que a an√°lise rodou

            # Exibir padr√µes detectados
            st.subheader("üìä Padr√µes Detectados")
            if st.session_state.padroes_detectados:
                df_padroes = pd.DataFrame(st.session_state.padroes_detectados)
                st.dataframe(df_padroes[['tipo', 'lado', 'desc', 'peso', 'janela']], use_container_width=True)
            else:
                st.warning("Nenhum padr√£o significativo detectado com a base de dados atual.")
                
            # --- Visualiza√ß√µes Gr√°ficas ---
            tab1, tab2, tab3 = st.tabs(["üìà Tend√™ncias", "üìä Distribui√ß√£o", "üß† Modelos"])
            
            with tab1:
                # Gr√°fico de tend√™ncia das somas
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=df_analise.index,
                    y=df_analise['Player'],
                    name='Player',
                    line=dict(color='#1f77b4', width=3)
                ))
                fig.add_trace(go.Scatter(
                    x=df_analise.index,
                    y=df_analise['Banker'],
                    name='Banker',
                    line=dict(color='#ff7f0e', width=3)
                ))
                fig.update_layout(
                    title='Evolu√ß√£o das Somas Player vs Banker',
                    xaxis_title='Rodada',
                    yaxis_title='Soma',
                    template='plotly_dark',
                    height=400
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Gr√°fico de diferen√ßas
                fig = px.bar(
                    df_analise,
                    x=df_analise.index,
                    y='Diferenca',
                    title='Diferen√ßa entre Player e Banker',
                    color='Resultado',
                    color_discrete_map={'P': '#1f77b4', 'B': '#ff7f0e', 'T': '#2ca02c'}
                )
                fig.update_layout(
                    template='plotly_dark',
                    height=350
                )
                st.plotly_chart(fig, use_container_width=True)
                
            with tab2:
                # Histograma comparativo
                fig = px.histogram(
                    df_analise,
                    x=['Player', 'Banker'],
                    nbins=11,
                    barmode='overlay',
                    opacity=0.7,
                    color_discrete_sequence=['#1f77b4', '#ff7f0e']
                )
                fig.update_layout(
                    title='Distribui√ß√£o das Somas',
                    xaxis_title='Soma',
                    yaxis_title='Frequ√™ncia',
                    template='plotly_dark',
                    height=400
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Gr√°fico de pizza de resultados
                result_counts = df_analise['Resultado'].value_counts()
                fig = px.pie(
                    result_counts,
                    values=result_counts.values,
                    names=result_counts.index,
                    title='Distribui√ß√£o de Resultados',
                    color=result_counts.index,
                    color_discrete_map={'P': '#1f77b4', 'B': '#ff7f0e', 'T': '#2ca02c'}
                )
                fig.update_layout(
                    template='plotly_dark',
                    height=350
                )
                st.plotly_chart(fig, use_container_width=True)
                
            with tab3:
                # Treinar e avaliar modelos
                # Adicionado `st.session_state.modelos_treinados` para controle
                if len(df_analise) > 50: # M√≠nimo de dados para train_test_split
                    st.subheader("Desempenho dos Modelos")
                    X = df_analise[["Player", "Banker"]]
                    y = df_analise["Resultado"]
                    
                    # Dividir dados
                    try:
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, test_size=0.2, random_state=42, stratify=y # Adicionado stratify para balancear classes
                        )
                    except ValueError as e:
                        st.warning(f"N√£o foi poss√≠vel dividir os dados para treinamento do modelo: {e}. Pode ser que uma classe tenha poucas amostras.")
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, test_size=0.2, random_state=42 # Remove stratify se der erro
                        )

                    # Aplicar StandardScaler antes de treinar modelos
                    scaler = StandardScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                    
                    resultados_modelos = []
                    for nome, modelo in MODELOS.items():
                        try:
                            start_time = time.time()
                            # Clone o modelo antes de treinar para garantir um novo estado em cada itera√ß√£o
                            m = modelo.__class__(**modelo.get_params())
                            m.fit(X_train_scaled, y_train)
                            y_pred = m.predict(X_test_scaled)
                            acc = accuracy_score(y_test, y_pred)
                            resultados_modelos.append({
                                "Modelo": nome,
                                "Acur√°cia": f"{acc*100:.1f}%",
                                "Tempo (s)": f"{time.time()-start_time:.3f}",
                                "Status": "‚úÖ" if acc > 0.6 else ("‚ö†Ô∏è" if acc > 0.5 else "‚ùå") # Crit√©rio mais claro
                            })
                        except Exception as e:
                            resultados_modelos.append({
                                "Modelo": nome,
                                "Acur√°cia": "ERRO",
                                "Tempo (s)": "N/A",
                                "Status": "‚ùå"
                            })
                    
                    df_resultados = pd.DataFrame(resultados_modelos)
                    st.dataframe(df_resultados, use_container_width=True)
                    
                    # Relat√≥rio de classifica√ß√£o
                    if st.checkbox("Mostrar relat√≥rio detalhado do melhor modelo", key="show_report_checkbox"):
                        if not df_resultados.empty and 'Acur√°cia' in df_resultados.columns:
                            # Converte 'Acur√°cia' para num√©rico para encontrar o m√°ximo
                            df_resultados['Acur√°cia_Num'] = df_resultados['Acur√°cia'].str.rstrip('%').astype(float) / 100
                            melhor_modelo_nome = df_resultados.loc[df_resultados['Acur√°cia_Num'].idxmax()]['Modelo']
                            
                            modelo_obj = MODELOS[melhor_modelo_nome]
                            # Retreinar o modelo para ter a inst√¢ncia exata se necess√°rio, ou usar a j√° treinada se o cache estiver ativo
                            m = modelo_obj.__class__(**modelo_obj.get_params()) # Clone para garantir
                            m.fit(X_train_scaled, y_train)
                            y_pred = m.predict(X_test_scaled)
                            
                            st.subheader(f"Relat√≥rio de Classifica√ß√£o - {melhor_modelo_nome}")
                            try:
                                report = classification_report(y_test, y_pred, output_dict=True)
                                df_report = pd.DataFrame(report).transpose()
                                st.dataframe(df_report.style.highlight_max(axis=0, color='#2a8c55'), use_container_width=True)
                            except ValueError as e:
                                st.warning(f"N√£o foi poss√≠vel gerar o relat√≥rio de classifica√ß√£o detalhado: {e}. Pode ser que algumas classes n√£o estejam presentes no conjunto de teste.")
                        else:
                            st.info("Nenhum resultado de modelo dispon√≠vel para gerar relat√≥rio.")
                    
                    # Informa√ß√£o sobre atualiza√ß√£o
                    if st.session_state.ultimo_treinamento:
                        st.caption(f"√öltimo treinamento dos modelos: {st.session_state.ultimo_treinamento.strftime('%d/%m/%Y %H:%M:%S')}")
                else:
                    st.warning("Dados insuficientes para treinar modelos de Machine Learning (m√≠nimo 50 registros).")
            
            # --- Backtesting ---
            st.subheader("üß™ Teste de Estrat√©gia")
            col_strat, col_size, col_run = st.columns([2, 1, 1])
            with col_strat:
                estrategia_selecionada = st.selectbox(
                    "Selecione a Estrat√©gia",
                    ["Simples (√öltimo Resultado)", "IA (Recomenda√ß√£o Inteligente)"],
                    index=0,
                    key="strategy_select"
                )
            with col_size:
                tamanho_janela_backtest = st.selectbox("Janela de An√°lise para Backtesting", [20, 30, 50, 100], index=0,
                                                       key="backtest_window_size")
            with col_run:
                st.write("") # Espa√ßo para alinhar o bot√£o
                if st.button("üîÅ Executar Backtesting", use_container_width=True):
                    if len(df_analise) >= tamanho_janela_backtest + 1: # Precisa de dados para a janela + 1 para o resultado
                        with st.spinner("Executando simula√ß√£o hist√≥rica..."):
                            # Seleciona estrat√©gia
                            if "Simples" in estrategia_selecionada:
                                resultados_backtest = executar_backtesting(df_analise, estrategia_simples, tamanho_janela_backtest)
                            else: # Estrat√©gia IA
                                resultados_backtest = executar_backtesting(df_analise, estrategia_ia, tamanho_janela_backtest)
                            
                            st.session_state.backtest_results = resultados_backtest
                            
                            if resultados_backtest: # Verifica se h√° resultados
                                # Exibir resultados
                                col1, col2, col3 = st.columns(3)
                                col1.metric("Saldo Inicial", f"R$1.000,00") # Sempre 1000
                                col2.metric("Saldo Final", f"R${resultados_backtest['saldo_final']:,.2f}",
                                            delta=f"{resultados_backtest['saldo_final']-1000:,.2f}")
                                col3.metric("Win Rate", f"{resultados_backtest['win_rate']:.1f}%")
                                st.metric("Retorno Total", f"{resultados_backtest['retorno_percent']:.1f}%",
                                          delta=f"{resultados_backtest['retorno_percent']:.1f}%")
                                
                                # Gr√°fico de evolu√ß√£o do saldo
                                df_evolucao = pd.DataFrame(resultados_backtest['detalhes'])
                                if not df_evolucao.empty:
                                    fig = px.line(
                                        df_evolucao,
                                        x='jogo',
                                        y='saldo',
                                        title='Evolu√ß√£o do Saldo no Backtesting',
                                        markers=True
                                    )
                                    fig.update_layout(
                                        xaxis_title='Rodada',
                                        yaxis_title='Saldo (R$)',
                                        template='plotly_dark'
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
                                else:
                                    st.info("Nenhuma aposta foi feita durante o backtesting ou os dados s√£o insuficientes.")

                                # An√°lise de acertos
                                st.subheader("An√°lise de Desempenho do Backtesting")
                                if resultados_backtest['acoes']:
                                    acoes_counts = pd.Series(resultados_backtest['acoes']).value_counts()
                                    fig = px.bar(
                                        acoes_counts,
                                        x=acoes_counts.index,
                                        y=acoes_counts.values,
                                        title='Distribui√ß√£o de Apostas no Backtesting',
                                        labels={'x': 'Aposta Recomendada', 'y': 'Quantidade'},
                                        color=acoes_counts.index,
                                        color_discrete_map={'P': '#1f77b4', 'B': '#ff7f0e', 'T': '#2ca02c'}
                                    )
                                    fig.update_layout(template='plotly_dark', showlegend=False)
                                    st.plotly_chart(fig, use_container_width=True)
                                else:
                                    st.info("Nenhuma aposta recomendada durante o backtesting para analisar.")
                            else:
                                st.error("Erro ao executar backtesting ou dados insuficientes ap√≥s filtragem.")
                    else:
                        st.warning(f"Necess√°rio m√≠nimo de {tamanho_janela_backtest + 1} registros para backtesting.")
            
            # Exibir resultados de backtesting se existirem
            if st.session_state.backtest_results:
                if 'saldo_final' in st.session_state.backtest_results:
                    st.info(f"√öltimo backtesting ({estrategia_selecionada}): "
                            f"Saldo Final R${st.session_state.backtest_results['saldo_final']:,.2f} | "
                            f"Win Rate {st.session_state.backtest_results['win_rate']:.1f}% | "
                            f"Retorno {st.session_state.backtest_results['retorno_percent']:.1f}%")
                else:
                    st.info("Nenhum resultado de backtesting dispon√≠vel. Execute o backtesting.")
            
            # --- Hist√≥rico de Recomenda√ß√µes ---
            st.subheader("üïí Hist√≥rico de Recomenda√ß√µes")
            if st.session_state.historico_recomendacoes:
                df_recomendacoes = pd.DataFrame(st.session_state.historico_recomendacoes)
                df_recomendacoes['timestamp'] = df_recomendacoes['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S') # Formatar para exibi√ß√£o
                df_recomendacoes = df_recomendacoes.sort_values('timestamp', ascending=False)
                # Selecionar colunas para exibi√ß√£o clara
                st.dataframe(df_recomendacoes[['timestamp', 'acao', 'confianca', 'tipo', 'detalhes']].head(10), use_container_width=True)
            else:
                st.info("Nenhuma recomenda√ß√£o registrada ainda.")
                
    else:
        st.info("‚ÑπÔ∏è Adicione mais dados para ativar a an√°lise preditiva (m√≠nimo 10 rodadas para an√°lise inicial).")
else:
    st.info("‚ÑπÔ∏è Adicione dados para ativar a an√°lise preditiva.")

# --- Rodap√© ---
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #aaa; font-size: 0.9em; padding: 20px;">
    BAC BO PREDICTOR PRO v2.1 | Sistema de An√°lise Preditiva | 
    Desenvolvido com Streamlit e Machine Learning | ¬© 2023-2024
</div>
""", unsafe_allow_html=True)
